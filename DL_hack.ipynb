{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VohEZeb1FuaI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the uploaded files\n",
        "train_zip_path = '/content/train_imageDL.zip'\n",
        "test_zip_path = '/content/test_imageDL.zip'\n",
        "train_csv_path = '/content/train_image.csv'\n",
        "test_csv_path = '/content/test_image.csv'\n",
        "train_extracted_path = '/content/train_imageDL_extracted'\n",
        "test_extracted_path = '/content/test_imageDL_extracted'"
      ],
      "metadata": {
        "id": "VepvLyDJHJT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to unzip files\n",
        "def unzip_file(zip_path, extract_to):\n",
        "    if os.path.exists(zip_path):\n",
        "        try:\n",
        "            os.makedirs(extract_to, exist_ok=True)\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_to)\n",
        "            print(f\"Extracted: {zip_path} to {extract_to}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting {zip_path}: {e}\")\n",
        "            raise\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"{zip_path} does not exist.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xKWTkbZsIRHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip train and test datasets\n",
        "unzip_file(train_zip_path, train_extracted_path)\n",
        "unzip_file(test_zip_path, test_extracted_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg1zw9ALeHz0",
        "outputId": "dde51272-bcc1-4d79-c723-3053562f94ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted: /content/train_imageDL.zip to /content/train_imageDL_extracted\n",
            "Extracted: /content/test_imageDL.zip to /content/test_imageDL_extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify extracted files\n",
        "print(\"Contents of train directory:\", os.listdir(train_extracted_path))\n",
        "print(\"Contents of test directory:\", os.listdir(test_extracted_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1LVQG9ueObF",
        "outputId": "2c075ddd-d7a7-4e57-f1c1-a802deec0835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of train directory: ['train']\n",
            "Contents of test directory: ['test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV files\n",
        "def load_csv(csv_path):\n",
        "    if os.path.exists(csv_path):\n",
        "        return pd.read_csv(csv_path)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"{csv_path} does not exist.\")\n",
        "\n",
        "train_csv = load_csv(train_csv_path)\n",
        "test_csv = load_csv(test_csv_path)\n"
      ],
      "metadata": {
        "id": "uOwndXxbeV1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update file paths based on labels\n",
        "real_path = os.path.join(train_extracted_path, \"train/training_real\")\n",
        "fake_path = os.path.join(train_extracted_path, \"train/training_fake\")\n",
        "\n",
        "train_csv['file_path'] = train_csv.apply(\n",
        "    lambda row: os.path.join(real_path, f\"{row['file_id']}.jpg\") if row['label'] == 1 else os.path.join(fake_path, f\"{row['file_id']}.jpg\"),\n",
        "    axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "s1bIdyc2ecHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets\n",
        "train_df, val_df = train_test_split(train_csv, test_size=0.2, stratify=train_csv['label'], random_state=42)\n"
      ],
      "metadata": {
        "id": "BZ9D7z5Qehh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify file existence\n",
        "print(\"\\nVerifying file paths in train_df:\")\n",
        "print(train_df['file_path'].apply(lambda x: os.path.exists(x)).value_counts())\n",
        "\n",
        "print(\"\\nVerifying file paths in val_df:\")\n",
        "print(val_df['file_path'].apply(lambda x: os.path.exists(x)).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0_7ux0yenCz",
        "outputId": "9e374d1a-8bf8-4b10-ca85-5850ea1bd1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verifying file paths in train_df:\n",
            "file_path\n",
            "True    1367\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Verifying file paths in val_df:\n",
            "file_path\n",
            "True    342\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMG_HEIGHT, IMG_WIDTH = 32, 32\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "OsI52PC_evQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data generator\n",
        "# Ensure labels are strings\n",
        "train_df['label'] = train_df['label'].astype(str)\n",
        "val_df['label'] = val_df['label'].astype(str)\n",
        "\n",
        "# Data Generators\n",
        "def create_data_generator(dataframe, datagen, target_size, batch_size, mode):\n",
        "    return datagen.flow_from_dataframe(\n",
        "        dataframe,\n",
        "        x_col='file_path',\n",
        "        y_col='label' if mode != 'test' else None,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary' if mode != 'test' else None,\n",
        "        shuffle=(mode != 'test')\n",
        "    )\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=10, zoom_range=0.2)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = create_data_generator(train_df, train_datagen, (IMG_HEIGHT, IMG_WIDTH), BATCH_SIZE, mode='train')\n",
        "val_generator = create_data_generator(val_df, val_datagen, (IMG_HEIGHT, IMG_WIDTH), BATCH_SIZE, mode='val')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be_cDypke0VA",
        "outputId": "e51863a0-bd57-4ac5-e4dc-3962de792e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1367 validated image filenames belonging to 2 classes.\n",
            "Found 342 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpoint_path = '/content/best_model.keras'\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True)\n"
      ],
      "metadata": {
        "id": "sUqlRWnofmeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Built from Scratch\n",
        "def build_model_from_scratch():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        BatchNormalization(),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Jmp3zMTPfx3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: Pre-trained ResNet50\n",
        "def build_pretrained_model():\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZTf81HOBf5CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models\n",
        "scratch_model = build_model_from_scratch()\n",
        "pretrained_model = build_pretrained_model()\n",
        "\n",
        "print(\"Training model from scratch...\")\n",
        "scratch_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")\n",
        "\n",
        "print(\"Training pre-trained model...\")\n",
        "pretrained_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtaN7kjbgCAk",
        "outputId": "f7ee3826-5467-4cc4-e34b-15e53744fb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model from scratch...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.5352 - loss: 1.0678 - val_accuracy: 0.5497 - val_loss: 0.6833\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 412ms/step - accuracy: 0.5686 - loss: 0.7709 - val_accuracy: 0.5556 - val_loss: 0.6856\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.5851 - loss: 0.7015 - val_accuracy: 0.5556 - val_loss: 0.7261\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 431ms/step - accuracy: 0.6116 - loss: 0.6660 - val_accuracy: 0.5585 - val_loss: 0.6848\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 437ms/step - accuracy: 0.6191 - loss: 0.6614 - val_accuracy: 0.5292 - val_loss: 0.6887\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 418ms/step - accuracy: 0.6381 - loss: 0.6293 - val_accuracy: 0.5585 - val_loss: 0.6825\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 426ms/step - accuracy: 0.6435 - loss: 0.6216 - val_accuracy: 0.5731 - val_loss: 0.6667\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 419ms/step - accuracy: 0.6818 - loss: 0.6040 - val_accuracy: 0.5673 - val_loss: 0.7132\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 419ms/step - accuracy: 0.6809 - loss: 0.5776 - val_accuracy: 0.5643 - val_loss: 0.6900\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 425ms/step - accuracy: 0.6529 - loss: 0.6010 - val_accuracy: 0.6140 - val_loss: 0.6810\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 414ms/step - accuracy: 0.6830 - loss: 0.6027 - val_accuracy: 0.5877 - val_loss: 0.6900\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 420ms/step - accuracy: 0.6925 - loss: 0.5682 - val_accuracy: 0.5906 - val_loss: 0.6650\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.6919 - loss: 0.5588 - val_accuracy: 0.5731 - val_loss: 0.7198\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 444ms/step - accuracy: 0.6696 - loss: 0.5880 - val_accuracy: 0.6082 - val_loss: 0.7583\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 409ms/step - accuracy: 0.7137 - loss: 0.5672 - val_accuracy: 0.5906 - val_loss: 0.7431\n",
            "Epoch 16/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 455ms/step - accuracy: 0.7001 - loss: 0.5835 - val_accuracy: 0.5702 - val_loss: 0.8910\n",
            "Epoch 17/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 403ms/step - accuracy: 0.7250 - loss: 0.5396 - val_accuracy: 0.5731 - val_loss: 0.7948\n",
            "Training pre-trained model...\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 586ms/step - accuracy: 0.5266 - loss: 0.9748 - val_accuracy: 0.5556 - val_loss: 0.6839\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 493ms/step - accuracy: 0.5347 - loss: 0.6938 - val_accuracy: 0.5556 - val_loss: 0.6887\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 509ms/step - accuracy: 0.4966 - loss: 0.7051 - val_accuracy: 0.5556 - val_loss: 0.6855\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 493ms/step - accuracy: 0.5326 - loss: 0.6941 - val_accuracy: 0.5556 - val_loss: 0.6865\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 487ms/step - accuracy: 0.5548 - loss: 0.6894 - val_accuracy: 0.5556 - val_loss: 0.6857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bee3625d810>"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_predictions(model, output_path):\n",
        "    # Ensure file_id is treated as a string\n",
        "    test_csv['file_id'] = test_csv['file_id'].astype(str)\n",
        "\n",
        "    # Rebuild file paths and validate\n",
        "    #test_csv['file_path'] = test_csv['file_id'].apply(lambda x: os.path.join(test_extracted_path, f\"{x}.jpg\"))\n",
        "    test_csv['file_path'] = test_csv['file_id'].apply(lambda x: os.path.join('/content/test_imageDL_extracted/test', f\"{x}.jpg\"))\n",
        "\n",
        "\n",
        "    # Verify file existence\n",
        "    missing_files = test_csv['file_path'].apply(lambda x: not os.path.exists(x)).sum()\n",
        "    if missing_files > 0:\n",
        "        print(f\"Warning: {missing_files} files are missing. Fix the file paths.\")\n",
        "        print(test_csv[test_csv['file_path'].apply(lambda x: not os.path.exists(x))].head())  # Show some missing paths\n",
        "        return\n",
        "\n",
        "    # Create test data generator\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_generator = create_data_generator(test_csv, test_datagen, (IMG_HEIGHT, IMG_WIDTH), 1, mode='test')\n",
        "\n",
        "    # Generate predictions\n",
        "    predictions = model.predict(test_generator)\n",
        "    predictions = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Save predictions\n",
        "    submission = pd.DataFrame({\n",
        "        'file_id': test_csv['file_id'],\n",
        "        'label': predictions\n",
        "    })\n",
        "    submission.to_csv(output_path, index=False)\n",
        "    print(f\"Submission file created at {output_path}\")\n"
      ],
      "metadata": {
        "id": "vziE2FKdivhO"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Verifying file paths in test_csv:\")\n",
        "print(test_csv['file_path'].head())  # Print a few file paths\n",
        "print(\"File existence check:\")\n",
        "print(test_csv['file_path'].apply(lambda x: os.path.exists(x)).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2KN7WDglodO",
        "outputId": "40fd0f26-bdc0-42ae-a645-ca947d90935a"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying file paths in test_csv:\n",
            "0    /content/test_imageDL_extracted/test/0.jpg\n",
            "1    /content/test_imageDL_extracted/test/1.jpg\n",
            "2    /content/test_imageDL_extracted/test/2.jpg\n",
            "3    /content/test_imageDL_extracted/test/3.jpg\n",
            "4    /content/test_imageDL_extracted/test/4.jpg\n",
            "Name: file_path, dtype: object\n",
            "File existence check:\n",
            "file_path\n",
            "True    332\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_test_predictions(scratch_model, '/content/submission_scratch.csv')\n",
        "generate_test_predictions(pretrained_model, '/content/submission_pretrained.csv')\n"
      ],
      "metadata": {
        "id": "xBrrwO4RkRzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0343c98-9c64-48f8-d341-8436ca76e05a"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 332 validated image filenames.\n",
            "\u001b[1m  6/332\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step\n",
            "Submission file created at /content/submission_scratch.csv\n",
            "Found 332 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 33ms/step\n",
            "Submission file created at /content/submission_pretrained.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate and calculate accuracy\n",
        "def evaluate_model_accuracy(model, val_generator):\n",
        "    # Predict on the validation data\n",
        "    val_predictions = model.predict(val_generator)\n",
        "    val_predictions = (val_predictions > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
        "\n",
        "    # Get true labels\n",
        "    val_labels = val_generator.labels  # The actual labels for the validation data\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(val_labels, val_predictions)\n",
        "    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Now, evaluate both models\n",
        "print(\"Evaluating scratch model on validation data...\")\n",
        "evaluate_model_accuracy(scratch_model, val_generator)\n",
        "\n",
        "print(\"Evaluating pre-trained model on validation data...\")\n",
        "evaluate_model_accuracy(pretrained_model, val_generator)\n"
      ],
      "metadata": {
        "id": "w8TrCiCSkTpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf74668-268b-4a77-dcd8-728bb0833bf5"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating scratch model on validation data...\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392ms/step\n",
            "Validation Accuracy: 47.37%\n",
            "Evaluating pre-trained model on validation data...\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 667ms/step\n",
            "Validation Accuracy: 55.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory where test images are located\n",
        "test_images_dir = '/content/test_imageDL_extracted/test'\n",
        "\n",
        "# Get the list of image filenames\n",
        "image_files = os.listdir(test_images_dir)\n",
        "\n",
        "# Create a DataFrame with 'file_id' and 'file_path'\n",
        "test_csv = pd.DataFrame({\n",
        "    'file_id': [i for i in range(len(image_files))],\n",
        "    'file_path': [os.path.join(test_images_dir, f) for f in image_files]\n",
        "})\n",
        "\n",
        "# Save this DataFrame to a CSV file\n",
        "test_csv.to_csv('/content/test_csv.csv', index=False)\n",
        "\n",
        "print(\"Test CSV file has been generated and saved as '/content/test_csv.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDb2RErKufQG",
        "outputId": "99accf3d-0839-46b7-d190-c0c0fa2a7302"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CSV file has been generated and saved as '/content/test_csv.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming predictions are made using your model and stored in 'predictions'\n",
        "# Here 'test_csv' contains the 'file_id' and 'file_path' for the test data\n",
        "\n",
        "# Predict labels using your model (assuming the model output is probabilities or class indices)\n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "\n",
        "# For multi-class classification, you might need to take the argmax of the probabilities\n",
        "predicted_labels = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# If the task is binary classification, predicted_labels can be a 0/1 prediction\n",
        "# If it is multi-class, the predicted labels will be indices of the predicted class\n",
        "\n",
        "# Add the predictions to the test_csv\n",
        "submission_df = test_csv.copy()\n",
        "submission_df['label'] = predicted_labels  # Add predicted labels to the dataframe\n",
        "\n",
        "# Save the submission CSV in the required format (file_id, label)\n",
        "submission_df[['file_id', 'label']].to_csv('/content/submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file saved as '/content/submission.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyhHRyaou3v8",
        "outputId": "8fb4e7a7-8021-4803-8602-bc910df7484a"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 322ms/step\n",
            "Submission file saved as '/content/submission.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your true labels file\n",
        "file_path = '/path_to_true_labels.csv'  # Replace with your actual path\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(file_path):\n",
        "    print(\"True labels file found. Loading the data...\")\n",
        "    # Assuming the true labels are in the 'label' column of the CSV\n",
        "    true_labels = pd.read_csv(file_path)['label'].values  # Adjust if column name is different\n",
        "else:\n",
        "    print(f\"True labels file not found at {file_path}\")\n",
        "\n",
        "# Assuming predictions are made using your model\n",
        "# Make sure that your model and test_generator are defined correctly\n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "\n",
        "# If your model outputs probabilities, convert to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=-1)  # This is for multi-class classification\n",
        "\n",
        "# Calculate accuracy if true labels and predicted labels are available\n",
        "if 'true_labels' in locals() and 'predicted_labels' in locals():\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"Could not compute accuracy due to missing data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeijhPhlwh0F",
        "outputId": "69650b18-f3de-4492-dc1a-7e6b476dcd87"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True labels file not found at /path_to_true_labels.csv\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 303ms/step\n",
            "Could not compute accuracy due to missing data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the correct path to your true labels file\n",
        "true_labels_file_path = '/content/true_labels.csv'  # Replace with your actual file path\n",
        "\n",
        "# Check if the file exists and load it\n",
        "if os.path.exists(true_labels_file_path):\n",
        "    print(\"True labels file found. Loading data...\")\n",
        "    true_labels_df = pd.read_csv(true_labels_file_path)\n",
        "    print(true_labels_df.head())  # Print first few rows to verify the column names\n",
        "    true_labels = true_labels_df['label'].values  # Make sure 'label' is the correct column name\n",
        "else:\n",
        "    print(f\"True labels file not found at {true_labels_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTlBxARFx3oe",
        "outputId": "d6fc451e-cbd1-4c97-b154-cac654d974fc"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True labels file not found at /content/true_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-2foxblwe9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import accuracy_score  # For calculating accuracy\n",
        "\n",
        "# Assuming you have the model loaded (scratch_model or pretrained_model)\n",
        "# Define the test data folder path\n",
        "test_folder_path = '/content/test_imageDL_extracted/test'  # Adjust path if necessary\n",
        "\n",
        "# Load the test CSV if you already have it\n",
        "test_csv = pd.read_csv('/content/test_csv.csv')  # Adjust path if necessary\n",
        "\n",
        "# Prepare the data generator for test data\n",
        "test_datagen = image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create the generator for test data (no labels are needed)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_csv,\n",
        "    directory=None,  # Since the file paths are already complete\n",
        "    x_col='file_path',\n",
        "    y_col=None,  # No labels for test data\n",
        "    class_mode=None,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),  # Adjust image size if necessary\n",
        "    batch_size=BATCH_SIZE,  # Adjust batch size as needed\n",
        "    shuffle=False  # Do not shuffle, to match filenames correctly\n",
        ")\n",
        "\n",
        "# Use your model to predict on the test set\n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "\n",
        "# If your model outputs probabilities (e.g., for a classification task), take the class with the highest probability\n",
        "predicted_labels = np.argmax(predictions, axis=1)  # Change this depending on your task\n",
        "\n",
        "# OPTIONAL: If ground truth is available (for evaluation purposes)\n",
        "# You can compare predicted labels with the actual labels\n",
        "# test_labels = test_csv['actual_labels']  # Replace this with your actual labels column (if available)\n",
        "# accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "\n",
        "# Now create the submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'file_id': test_csv['file_id'],\n",
        "    'label': predicted_labels\n",
        "})\n",
        "\n",
        "# If ground truth is available, you can add accuracy to the CSV\n",
        "# submission_df['accuracy'] = accuracy  # Only if you want to include the accuracy in the CSV file\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "submission_df.to_csv('/content/submission_dl.csv', index=False)\n",
        "\n",
        "# If you want to print accuracy and other metrics:\n",
        "print(\"Accuracy of the model on test data:\", accuracy)  # If accuracy is calculated\n",
        "\n",
        "print(\"Submission CSV has been saved as '/content/submission.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Z-pLMajnuHAK",
        "outputId": "77947a0c-84b7-4640-e943-e4cb317b88ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/test_csv.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-38f1bac113f8>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load the test CSV if you already have it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test_csv.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust path if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Prepare the data generator for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/test_csv.csv'"
          ]
        }
      ]
    }
  ]
}